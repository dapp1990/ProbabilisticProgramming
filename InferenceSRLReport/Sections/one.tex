\section{Probabilistic Inference Using Weighted Model Counting}
\subsection{PGM to CNF}

Table~\ref{variableDescription} shows the semantics of the domain variables used for those tasks.

Tables~\ref{logicalEnc1} and~\ref{logicalEnc2} show the logical variables used for encoding the Bayesian Network.

Table~\ref{cnfRepresentationEnc1} represents the encoded Bayesian Network using ENC1 and table~\ref{weightsEnc1} contains the corresponding weights. Table~\ref{cnfFullRepresentationEnc1} shows the fully expanded CNF from table~\ref{cnfRepresentationEnc1}.

Likewise, table~\ref{cnfRepresentationEnc2} represents the encoded Bayesian Network using ENC2 and table~\ref{weightsEnc2} contains the corresponding weights. Table~\ref{cnfRepresentationEnc2_expand} shows the fully expanded CNF from table~\ref{cnfRepresentationEnc2}.

\textit{The variables that are not listed in table~\ref{weightsEnc1} and table~\ref{weightsEnc2}, have a weight equal to 1. }

\input{Tables/variableDescription}
\input{Tables/logicalEnc1}
\input{Tables/logicalEnc2}

\input{Tables/cnfRepresentationEnc1}
\input{Tables/weightsEnc1}
\input{Tables/cnfRepresentationEnc1Expanded}

\input{Tables/cnfRepresentationEnc2}
\input{Tables/weightsEnc2}
\input{Tables/cnfRepresentationEnc2_expand}

\subsection{SRL to CNF}

First the program must be grounded, while taking into account \textbf{Q} and \textbf{E}. In this case the evidence set \textbf{E} is empty (there is no evidence available). The grounding process of the queries will be described step-by-step in listings~\ref{lst:query15} and~\ref{lst:query16}.  If only \textbf{query(path(1,5))} was considered, then \textbf{edge(5,6)} and \textbf{edge(2,6)} would have been irrelevant. With the inclusion of \textbf{query(path(1,6))} all edges become relevant.

\input{Listings/12_querygrounding}

The second step is to find an equivalent CNF of the ground program. Given the grounded rules \mbox{\textbf{w :- r}} and \mbox{\textbf{w :- s}}, the equivalent CNF contains the following three clauses: $\neg r \lor w$, $\neg s \lor w$ and $\neg w \lor s \lor r$. In our case $r$ and $s$ both are conjunctions, so De Morgans law is used to write the first two clauses. For the last clause, all permutations of the combinations of the elements $\neg w$, $r$ and $s$ are considered. For \textbf{path(1,5)} this yields $2*3 = 6$ combinations. For \textbf{path(1,6)} there are $2*3*4 = 24$ combinations. The CNF is shown in table~\ref{table:12cnf}. Note that on the last big block of $path_{16}$ that the \textit{and} operators can be removed, and the separate clauses can be listed underneath each other. We chose to use the current format because the resulting table would become too large (vertically) otherwise. It also clearly shows which clauses corresponds to the 24 combinations.

\input{Tables/12_cnf}

The final step is to obtain a weighted CNF. Since there's no evidence in our example, the CNF remains the same as shown in table~\ref{table:12cnf}. Table~\ref{table:12weight} displays the weighted literals. The weights for $path_{15}$, $path_{16}$, $\neg path_{15}$ and $\neg path_{16}$ equal 1 because they're defined in clauses. The weight of any world $\omega$ can be calculated as the product of the weight of all literals in $\omega$. For example, the world ${path_{15}, edge_{12}, edge_{25}, edge_{13}, edge_{34}, \neg edge_{45}}$ has the weight $0.6*0.4*0.1*0.3*0.2 = 0.00144$.

\input{Tables/12_weights}


\subsection{Weighted Model Counting}

We used the following exact model counters: \textbf{MiniC2D}, \textbf{SDD} and \textbf{sharpSAT}.
\\[2ex]
MiniC2D uses exhaustive DPLL, a backtracking based search algorithm to solve the \textit{boolean satisfiability problem}. It compiles CNFs into Decision-SDDs for the knowledge compilation, using a top-down approach. The top-down approach is considered to be faster by \textit{Umut Oztok and Adnan Darwiche}\cite{oztok2015top}. The Decision-SDDs are a subset of SDDs which facilitate the top-down compilation of SDDs.
\\[2ex]
The SDD program is similar to MiniC2D in the sense that it compiles CNFs into SDD datastructures. The shape of the SDD can be manipulated to improve efficiency, as will be explained in section~\ref{subsec:knowledgecompilation}.
\\[2ex]
sharpSAT also uses DPLL, but combines this with \textit{look ahead} technique that is based on \textit{boolean constraint propagation}~\cite{thurley2006sharpsat}. The look ahead technique eliminates more variables that can not be part of a solution, and thus reduces the search space to backtrack over.
\\[2ex]
Table~\ref{table:comptask1enc1} to table~\ref{table:comptask2} show the computational requirements of each exact model counter on the CNF from task 1 with encoding 1, task 1 with encoding 2 and task 2 respectively. There are 36 variables 94 clauses. \textit{The CNF encodings are included with our program.}


\begin{table}[h]
	\centering
	\caption{Computational requirements task 1 ENC1.}
	\label{table:comptask1enc1}
	\begin{tabular}{l|l|l|l}
		\textbf{}        & \textbf{miniC2D} & \textbf{SDD} & \textbf{sharpSAT} \\ \hline
		\textbf{total runtime} &  0.019s  &   0.044s   &   0.008s  \\ \hline
		\textbf{memory (cache size)}  &  0.011MB  &   0.3MB &   7MB  \\ \hline
		\textbf{cache hit rate}  & 66.7\%  & 85.2\% &   100\%
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{Computational requirements task 1 ENC2.}
	\label{table:comptask1enc2}
	\begin{tabular}{l|l|l|l}
		\textbf{}        & \textbf{miniC2D} & \textbf{SDD} & \textbf{sharpSAT} \\ \hline
		\textbf{total runtime} &  0.017s  &   0.028s   &   0.004s  \\ \hline
		\textbf{memory (cache size)}  &  0.007MB  &   0.2MB &   7MB  \\ \hline
		\textbf{cache hit rate}  & 43.4\%  & 84.2\% &   100\%
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{Computational requirements task 2.}
	\label{table:comptask2}
	\begin{tabular}{l|l|l|l}
		\textbf{}        & \textbf{miniC2D} & \textbf{SDD} & \textbf{sharpSAT} \\ \hline
		\textbf{total runtime} &  0.020s  &   0.001s   &   0.005s  \\ \hline
		\textbf{memory (cache size)}  &  0.002MB  &   0.0MB &   7MB  \\ \hline
		\textbf{cache hit rate}  & 40.0\%  & 84.4\% &   100\%
	\end{tabular}
\end{table}

\subsection{Knowledge Compilation}\label{subsec:knowledgecompilation}

We use \textbf{MiniC2D} as tool for this section.
\\[2ex]
We tested different scenarios for the first two CNF file (with evidence, no evidence and some queries). Likewise we tested the CNF constructed in section 2 separately, considering the grounded queries for path 1-5 and 1-6.
\\[2ex]
Table~\ref{vtree_11_enc1_no_evidence} to table~\ref{vtree_12_srl2cnf_query_path16} show the results of the different experiments. According with those, the best heuristic that gave us the most compact circuit is the natural elimination order method with incidence graph type, even though natural elimination order method with primal graph type gave the fastest result. This pattern is consistent in all the experiments were done.
\\[2ex]
The final conclusion is that natural elimination order method with incidence graph type would work better with DPLL because can increase the inference process due to the small circuit of the vtree. This would pay off the extra time that is needed to construct it compared to primal graph.

\input{Tables/vtree_11_enc1_no_evidence}
\input{Tables/vtree_11_enc1_query_burglary}
\input{Tables/vtree_11_enc1_query_earthquak_heavy}
\input{Tables/vtree_11_enc1_with_evidence}
\input{Tables/vtree_11_enc2_no_evidence}
\input{Tables/vtree_11_enc2_query_burglary}
\input{Tables/vtree_11_enc2_with_evidence}
\input{Tables/vtree_12_srl2cnf_query_path15}
\input{Tables/vtree_12_srl2cnf_query_path16}
