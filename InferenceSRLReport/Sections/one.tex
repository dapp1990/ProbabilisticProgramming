\section{Probabilistic Inference Using Weighted Model Counting}
\subsection{PGM to CNF}

Table~\ref{variableDescription} shows the semantics of the domain variables used for those tasks.

Tables~\ref{logicalEnc1} and~\ref{logicalEnc2} show the logical variables used for encoding the Bayesian Network.

Table~\ref{cnfRepresentationEnc1} represents the encoded Bayesian Network using ENC1 and table~\ref{weightsEnc1} contains the corresponding weights. Table~\ref{cnfFullRepresentationEnc1} shows the fully expanded CNF from table~\ref{cnfRepresentationEnc1}.

Likewise, table~\ref{cnfRepresentationEnc2} represents the encoded Bayesian Network using ENC2 and table~\ref{weightsEnc2} contains the corresponding weights. Table~\ref{cnfRepresentationEnc2_expand} shows the fully expanded CNF from table~\ref{cnfRepresentationEnc2}.

\textit{The variables that are not listed in table~\ref{weightsEnc1} and table~\ref{weightsEnc2}, have a weight equal to 1. }

\input{Tables/variableDescription}
\input{Tables/logicalEnc1}
\input{Tables/logicalEnc2}

\input{Tables/cnfRepresentationEnc1}
\input{Tables/weightsEnc1}
\input{Tables/cnfRepresentationEnc1Expanded}

\input{Tables/cnfRepresentationEnc2}
\input{Tables/weightsEnc2}
\input{Tables/cnfRepresentationEnc2_expand}

\subsection{SRL to CNF}

First the program must be grounded, while taking into account \textbf{Q} and \textbf{E}. In this case the evidence set \textbf{E} is empty (there is no evidence available). The grounding process of the queries will be described step-by-step in listings~\ref{lst:query15} and~\ref{lst:query16}.  If only \textbf{query(path(1,5))} was considered, then \textbf{edge(5,6)} and \textbf{edge(2,6)} would have been irrelevant. With the inclusion of \textbf{query(path(1,6))} all edges become relevant.

\input{Listings/12_querygrounding}

The second step is to find an equivalent CNF of the ground program. Given the grounded rules \mbox{\textbf{w :- r}} and \mbox{\textbf{w :- s}}, the equivalent CNF contains the following three clauses: $\neg r \lor w$, $\neg s \lor w$ and $\neg w \lor s \lor r$. In our case $r$ and $s$ both are conjunctions, so De Morgans law is used to write the first two clauses. For the last clause, all permutations of the combinations of the elements $\neg w$, $r$ and $s$ are considered. For \textbf{path(1,5)} this yields $2*3 = 6$ combinations. For \textbf{path(1,6)} there are $2*3*4 = 24$ combinations. The CNF is shown in table~\ref{table:12cnf}. Note that on the last big block of $path_{16}$ that the \textit{and} operators can be removed, and the separate clauses can be listed underneath each other. We chose to use the current format because the resulting table would become too large (vertically) otherwise. It also clearly shows which clauses corresponds to the 24 combinations.

\input{Tables/12_cnf}

The final step is to obtain a weighted CNF. Since there's no evidence in our example, the CNF remains the same as shown in table~\ref{table:12cnf}. Table~\ref{table:12weight} displays the weighted literals. The weights for $path_{15}$, $path_{16}$, $\neg path_{15}$ and $\neg path_{16}$ equal 1 because they're defined in clauses. The weight of any world $\omega$ can be calculated as the product of the weight of all literals in $\omega$. For example, the world ${path_{15}, edge_{12}, edge_{25}, edge_{13}, edge_{34}, \neg edge_{45}}$ has the weight $0.6*0.4*0.1*0.3*0.2 = 0.00144$.

\input{Tables/12_weights}


\subsection{Weighted Model Counting}

We used the following exact model counters: \textbf{MiniC2D}, \textbf{SDD} and \textbf{sharpSAT}.
\\[2ex]
MiniC2D uses exhaustive DPLL, a backtracking based search algorithm to solve the \textit{boolean satisfiability problem}. It compiles CNFs into Decision-SDDs for the knowledge compilation, using a top-down approach. The top-down approach is considered to be faster by \textit{Umut Oztok and Adnan Darwiche}\cite{oztok2015top}. The Decision-SDDs are a subset of SDDs which facilitate the top-down compilation of SDDs.
\\[2ex]
The SDD program is similar to MiniC2D in the sense that it compiles CNFs into SDD datastructures. The shape of the SDD can be manipulated to improve efficiency, as will be explained in section~\ref{subsec:knowledgecompilation}.
\\[2ex]
sharpSAT also uses DPLL, but combines this with \textit{look ahead} technique that is based on \textit{boolean constraint propagation}~\cite{thurley2006sharpsat}. The look ahead technique eliminates more variables that can not be part of a solution, and thus reduces the search space to backtrack over.
\\[2ex]
Table~\ref{table:comptask1enc1} to table~\ref{table:comptask2} show the computational requirements of each exact model counter on the CNF from task 1 with encoding 1, task 1 with encoding 2 and task 2 respectively. There are 36 variables 94 clauses. \textit{The CNF encodings are included with our program.}


\begin{table}[h]
	\centering
	\caption{Computational requirements task 1 ENC1.}
	\label{table:comptask1enc1}
	\begin{tabular}{l|l|l|l}
		\textbf{}        & \textbf{miniC2D} & \textbf{SDD} & \textbf{sharpSAT} \\ \hline
		\textbf{total runtime} &  0.019s  &   0.044s   &   0.008s  \\ \hline
		\textbf{memory (cache size)}  &  0.011MB  &   0.3MB &   7MB  \\ \hline
		\textbf{cache hit rate}  & 66.7\%  & 85.2\% &   100\%
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{Computational requirements task 1 ENC2.}
	\label{table:comptask1enc2}
	\begin{tabular}{l|l|l|l}
		\textbf{}        & \textbf{miniC2D} & \textbf{SDD} & \textbf{sharpSAT} \\ \hline
		\textbf{total runtime} &  0.017s  &   0.028s   &   0.004s  \\ \hline
		\textbf{memory (cache size)}  &  0.007MB  &   0.2MB &   7MB  \\ \hline
		\textbf{cache hit rate}  & 43.4\%  & 84.2\% &   100\%
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{Computational requirements task 2.}
	\label{table:comptask2}
	\begin{tabular}{l|l|l|l}
		\textbf{}        & \textbf{miniC2D} & \textbf{SDD} & \textbf{sharpSAT} \\ \hline
		\textbf{total runtime} &  0.020s  &   0.001s   &   0.005s  \\ \hline
		\textbf{memory (cache size)}  &  0.002MB  &   0.0MB &   7MB  \\ \hline
		\textbf{cache hit rate}  & 40.0\%  & 84.4\% &   100\%
	\end{tabular}
\end{table}

\subsection{Knowledge Compilation}\label{subsec:knowledgecompilation}

We used \textbf{MiniC2D} knowledge compiler a as tools for this section.
\\[2ex]
We tested different scenarios for the CNFs of tasks 1.1 and 1.2 (with evidence, no evidence and some queries). Likewise, we tested the CNFs constructed in tasks 1.3 separately, considering the grounded queries for path(1,5) and path(1,6).
\\[2ex]
Table~\ref{vtree_11_enc1_no_evidence} to table~\ref{vtree_12_srl2cnf_query_path16} show the results of the different experiments. According with the results, the best heuristic that gave us the most compact circuit was the \testit{natural elimination order} method with \testit{incidence graph} type, even though \testit{natural elimination order} method with \testit{primal graph} type showed the best performs in terms of time.
\\[2ex]
The CNF of tasks 1.3 (tables ~\ref{vtree_12_srl2cnf_query_path15} and ~\ref{vtree_12_srl2cnf_query_path16}) presented difference results, \textit{natural elimination order} was the worst.
\\[2ex]
Furthermore, we compared the different vtree parameters in the grounded CNF given by the pipeline described in section II; results are shown in table ~\ref{vtree_network_query_hrekg}. We obtained similar result than CNF of tasks 1.3, \textit{natural elimination order} showed the widest circuits. \textit{Natural elimination order} was even worst when it was used on combination with \textit{incident graph}. We could not fetch a result after 5 minutes of waiting.
\\[2ex]
We concluded that the grounding process is an important factor to choose wisely the proper configuration for the creation of the vtrees. Additionally, we concluded that \textit{incident graph} performs better than \textit{primal graph} when it is used on combination with \textit{hypergraph with fixed balance factor} method. This assumption highly relies on the results of table~\ref{vtree_network_query_hrekg} since the other CNFs show a slightly variation on the vtree circuit.
\\[2ex]

\input{Tables/vtree_11_enc1_no_evidence}
\input{Tables/vtree_11_enc1_query_burglary}
\input{Tables/vtree_11_enc1_query_earthquak_heavy}
\input{Tables/vtree_11_enc1_with_evidence}
\input{Tables/vtree_11_enc2_no_evidence}
\input{Tables/vtree_11_enc2_query_burglary}
\input{Tables/vtree_11_enc2_with_evidence}
\input{Tables/vtree_12_srl2cnf_query_path15}
\input{Tables/vtree_12_srl2cnf_query_path16}
\input{Tables/vtree_network_query_hrekg}
